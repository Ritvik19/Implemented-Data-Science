{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f971a7f",
   "metadata": {
    "papermill": {
     "duration": 0.007279,
     "end_time": "2022-07-02T09:40:56.684365",
     "exception": false,
     "start_time": "2022-07-02T09:40:56.677086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Quantization \n",
    "Post-training quantization includes general techniques to reduce CPU and hardware accelerator latency, processing, power, and model size with little degradation in model accuracy. These techniques can be performed on an already-trained float TensorFlow model and applied during TensorFlow Lite conversion.Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6db81b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-02T09:40:56.700230Z",
     "iopub.status.busy": "2022-07-02T09:40:56.699503Z",
     "iopub.status.idle": "2022-07-02T09:41:05.601438Z",
     "shell.execute_reply": "2022-07-02T09:41:05.600213Z"
    },
    "papermill": {
     "duration": 8.913484,
     "end_time": "2022-07-02T09:41:05.604695",
     "exception": false,
     "start_time": "2022-07-02T09:40:56.691211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d819579",
   "metadata": {
    "papermill": {
     "duration": 0.00629,
     "end_time": "2022-07-02T09:41:05.617912",
     "exception": false,
     "start_time": "2022-07-02T09:41:05.611622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3998c9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:05.634353Z",
     "iopub.status.busy": "2022-07-02T09:41:05.633115Z",
     "iopub.status.idle": "2022-07-02T09:41:49.762677Z",
     "shell.execute_reply": "2022-07-02T09:41:49.761251Z"
    },
    "papermill": {
     "duration": 44.141055,
     "end_time": "2022-07-02T09:41:49.765603",
     "exception": false,
     "start_time": "2022-07-02T09:41:05.624548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:07.946487: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-02 09:41:08.275550: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2569 - accuracy: 0.9286 - val_loss: 0.1033 - val_accuracy: 0.9702\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0935 - accuracy: 0.9730 - val_loss: 0.0703 - val_accuracy: 0.9781\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0706 - accuracy: 0.9798 - val_loss: 0.0631 - val_accuracy: 0.9808\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0590 - accuracy: 0.9827 - val_loss: 0.0597 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0513 - accuracy: 0.9850 - val_loss: 0.0570 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f583cb599d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = (train_images / 255.0).astype(np.float32)\n",
    "test_images = (test_images / 255.0).astype(np.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=5,\n",
    "  validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5c3ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:49.872729Z",
     "iopub.status.busy": "2022-07-02T09:41:49.872231Z",
     "iopub.status.idle": "2022-07-02T09:41:49.901553Z",
     "shell.execute_reply": "2022-07-02T09:41:49.900537Z"
    },
    "papermill": {
     "duration": 0.085594,
     "end_time": "2022-07-02T09:41:49.904024",
     "exception": false,
     "start_time": "2022-07-02T09:41:49.818430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_dir = pathlib.Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "model.save(f'{models_dir}/tf_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d7aa",
   "metadata": {
    "papermill": {
     "duration": 0.051227,
     "end_time": "2022-07-02T09:41:50.007298",
     "exception": false,
     "start_time": "2022-07-02T09:41:49.956071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Various Quantization Techniques\n",
    "\n",
    "**Convert to a TensorFlow Lite model**\n",
    "\n",
    "TensorFlow Lite converts weights to 8 bit precision as part of model conversion from tensorflow graphdefs to TensorFlow Lite's flat buffer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aabe405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:50.115678Z",
     "iopub.status.busy": "2022-07-02T09:41:50.114861Z",
     "iopub.status.idle": "2022-07-02T09:41:51.365720Z",
     "shell.execute_reply": "2022-07-02T09:41:51.364495Z"
    },
    "papermill": {
     "duration": 1.307187,
     "end_time": "2022-07-02T09:41:51.368165",
     "exception": false,
     "start_time": "2022-07-02T09:41:50.060978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:50.483282: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-07-02 09:41:51.161867: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-02 09:41:51.162069: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-02 09:41:51.166275: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-07-02 09:41:51.225119: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-07-02 09:41:51.225214: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-07-02 09:41:51.268137: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-07-02 09:41:51.301923: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_file = models_dir/\"tflite_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b885a4",
   "metadata": {
    "papermill": {
     "duration": 0.053116,
     "end_time": "2022-07-02T09:41:51.473945",
     "exception": false,
     "start_time": "2022-07-02T09:41:51.420829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dynamic Quantization**\n",
    "\n",
    "The simplest form of post-training quantization statically quantizes only the weights from floating point to integer, which has 8-bits of precision\n",
    "\n",
    "At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec6e3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:51.581364Z",
     "iopub.status.busy": "2022-07-02T09:41:51.580954Z",
     "iopub.status.idle": "2022-07-02T09:41:52.445661Z",
     "shell.execute_reply": "2022-07-02T09:41:52.444343Z"
    },
    "papermill": {
     "duration": 0.921908,
     "end_time": "2022-07-02T09:41:52.448838",
     "exception": false,
     "start_time": "2022-07-02T09:41:51.526930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:52.373388: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-02 09:41:52.373599: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-02 09:41:52.375221: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-07-02 09:41:52.415433: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-07-02 09:41:52.415490: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-07-02 09:41:52.436544: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential/conv2d/Conv2D because it has fewer than 1024 elements (108).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23904"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_dynamic_quant_model = converter.convert()\n",
    "tflite_dynamic_quant_model_file = models_dir/\"tflite_dynamic_quant_model.tflite\"\n",
    "tflite_dynamic_quant_model_file.write_bytes(tflite_dynamic_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada98b35",
   "metadata": {
    "papermill": {
     "duration": 0.052176,
     "end_time": "2022-07-02T09:41:52.554221",
     "exception": false,
     "start_time": "2022-07-02T09:41:52.502045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Integer Quantization**\n",
    "\n",
    "Integer quantization is an optimization strategy that converts 32-bit floating-point numbers (such as weights and activation outputs) to the nearest 8-bit fixed-point numbers. This results in a smaller model and increased inferencing speed.\n",
    "\n",
    "To quantize the variable data (such as model input/output and intermediates between layers), you need to provide a RepresentativeDataset. This is a generator function that provides a set of input data that's large enough to represent typical values. It allows the converter to estimate a dynamic range for all the variable data. (The dataset does not need to be unique compared to the training or evaluation dataset.) To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80fd7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:52.661731Z",
     "iopub.status.busy": "2022-07-02T09:41:52.660716Z",
     "iopub.status.idle": "2022-07-02T09:41:54.019868Z",
     "shell.execute_reply": "2022-07-02T09:41:54.018513Z"
    },
    "papermill": {
     "duration": 1.415692,
     "end_time": "2022-07-02T09:41:54.022299",
     "exception": false,
     "start_time": "2022-07-02T09:41:52.606607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:53.447634: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-02 09:41:53.447831: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-02 09:41:53.449489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2022-07-02 09:41:53.487386: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-07-02 09:41:53.487444: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 \n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_int_quant_model = converter.convert()\n",
    "tflite_int_quant_model_file = models_dir/\"tflite_int_quant_model.tflite\"\n",
    "tflite_int_quant_model_file.write_bytes(tflite_dynamic_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b01e2",
   "metadata": {
    "papermill": {
     "duration": 0.052313,
     "end_time": "2022-07-02T09:41:54.128741",
     "exception": false,
     "start_time": "2022-07-02T09:41:54.076428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Float 16 Quantization**\n",
    "\n",
    "Converting weights to 16-bit floating point values during model conversion from TensorFlow to TensorFlow Lite's flat buffer format, results in a 2x reduction in model size. Some hardware, like GPUs, can compute natively in this reduced precision arithmetic, realizing a speedup over traditional floating point execution. The Tensorflow Lite GPU delegate can be configured to run in this way. However, a model converted to float16 weights can still run on the CPU without additional modification: the float16 weights are upsampled to float32 prior to the first inference. This permits a significant reduction in model size in exchange for a minimal impacts to latency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b364b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:54.236749Z",
     "iopub.status.busy": "2022-07-02T09:41:54.236067Z",
     "iopub.status.idle": "2022-07-02T09:41:55.095534Z",
     "shell.execute_reply": "2022-07-02T09:41:55.093884Z"
    },
    "papermill": {
     "duration": 0.917442,
     "end_time": "2022-07-02T09:41:55.098700",
     "exception": false,
     "start_time": "2022-07-02T09:41:54.181258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:55.023192: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-02 09:41:55.023384: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-02 09:41:55.024990: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-07-02 09:41:55.064130: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-07-02 09:41:55.064188: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44432"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_float16_quant_model = converter.convert()\n",
    "tflite_float16_quant_model_file = models_dir/\"tflite_float16_quant_model.tflite\"\n",
    "tflite_float16_quant_model_file.write_bytes(tflite_float16_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d9af0",
   "metadata": {
    "papermill": {
     "duration": 0.052687,
     "end_time": "2022-07-02T09:41:55.204891",
     "exception": false,
     "start_time": "2022-07-02T09:41:55.152204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**16x8 Quantization**\n",
    "\n",
    "Converting activations to 16-bit integer values and weights to 8-bit integer values during model conversion from TensorFlow to TensorFlow Lite's flat buffer format can improve accuracy of the quantized model significantly, when activations are sensitive to the quantization, while still achieving almost 3-4x reduction in model size. Moreover, this fully quantized model can be consumed by integer-only hardware accelerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0864dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:55.312029Z",
     "iopub.status.busy": "2022-07-02T09:41:55.311628Z",
     "iopub.status.idle": "2022-07-02T09:41:56.170929Z",
     "shell.execute_reply": "2022-07-02T09:41:56.170082Z"
    },
    "papermill": {
     "duration": 0.916698,
     "end_time": "2022-07-02T09:41:56.174076",
     "exception": false,
     "start_time": "2022-07-02T09:41:55.257378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 09:41:56.101622: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-02 09:41:56.101813: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-02 09:41:56.103597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-07-02 09:41:56.141870: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-07-02 09:41:56.141923: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-07-02 09:41:56.163118: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential/conv2d/Conv2D because it has fewer than 1024 elements (108).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "tflite_16x8_quant_model = converter.convert()\n",
    "tflite_16x8_quant_model_file = models_dir/\"tflite_16x8_quant_model.tflite\"\n",
    "tflite_16x8_quant_model_file.write_bytes(tflite_16x8_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2320323",
   "metadata": {
    "papermill": {
     "duration": 0.052823,
     "end_time": "2022-07-02T09:41:56.279836",
     "exception": false,
     "start_time": "2022-07-02T09:41:56.227013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afe4a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:56.389304Z",
     "iopub.status.busy": "2022-07-02T09:41:56.388680Z",
     "iopub.status.idle": "2022-07-02T09:41:57.169892Z",
     "shell.execute_reply": "2022-07-02T09:41:57.168660Z"
    },
    "papermill": {
     "duration": 0.838567,
     "end_time": "2022-07-02T09:41:57.172636",
     "exception": false,
     "start_time": "2022-07-02T09:41:56.334069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 476\r\n",
      "drwxr-xr-x 2 root root   4096 Jul  2 09:41 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 3 root root   4096 Jul  2 09:41 \u001b[01;34m..\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 271416 Jul  2 09:41 tf_model.h5\r\n",
      "-rw-r--r-- 1 root root  23904 Jul  2 09:41 tflite_16x8_quant_model.tflite\r\n",
      "-rw-r--r-- 1 root root  23904 Jul  2 09:41 tflite_dynamic_quant_model.tflite\r\n",
      "-rw-r--r-- 1 root root  44432 Jul  2 09:41 tflite_float16_quant_model.tflite\r\n",
      "-rw-r--r-- 1 root root  23904 Jul  2 09:41 tflite_int_quant_model.tflite\r\n",
      "-rw-r--r-- 1 root root  84500 Jul  2 09:41 tflite_model.tflite\r\n"
     ]
    }
   ],
   "source": [
    "ls -la models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b071233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:57.281898Z",
     "iopub.status.busy": "2022-07-02T09:41:57.281076Z",
     "iopub.status.idle": "2022-07-02T09:41:57.291356Z",
     "shell.execute_reply": "2022-07-02T09:41:57.290593Z"
    },
    "papermill": {
     "duration": 0.067598,
     "end_time": "2022-07-02T09:41:57.293494",
     "exception": false,
     "start_time": "2022-07-02T09:41:57.225896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for test_image in test_images:\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_digits)):\n",
    "        if prediction_digits[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69fd4cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:57.401267Z",
     "iopub.status.busy": "2022-07-02T09:41:57.400717Z",
     "iopub.status.idle": "2022-07-02T09:41:58.994739Z",
     "shell.execute_reply": "2022-07-02T09:41:58.993651Z"
    },
    "papermill": {
     "duration": 1.650716,
     "end_time": "2022-07-02T09:41:58.997123",
     "exception": false,
     "start_time": "2022-07-02T09:41:57.346407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efcf01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:41:59.105038Z",
     "iopub.status.busy": "2022-07-02T09:41:59.104674Z",
     "iopub.status.idle": "2022-07-02T09:42:00.703043Z",
     "shell.execute_reply": "2022-07-02T09:42:00.701929Z"
    },
    "papermill": {
     "duration": 1.655609,
     "end_time": "2022-07-02T09:42:00.705638",
     "exception": false,
     "start_time": "2022-07-02T09:41:59.050029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_dynamic_quant = tf.lite.Interpreter(model_path=str(tflite_dynamic_quant_model_file))\n",
    "interpreter_dynamic_quant.allocate_tensors()\n",
    "evaluate_model(interpreter_dynamic_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53e8675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:42:00.817253Z",
     "iopub.status.busy": "2022-07-02T09:42:00.816587Z",
     "iopub.status.idle": "2022-07-02T09:42:02.458740Z",
     "shell.execute_reply": "2022-07-02T09:42:02.457761Z"
    },
    "papermill": {
     "duration": 1.70051,
     "end_time": "2022-07-02T09:42:02.461069",
     "exception": false,
     "start_time": "2022-07-02T09:42:00.760559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_int_quant = tf.lite.Interpreter(model_path=str(tflite_int_quant_model_file))\n",
    "interpreter_int_quant.allocate_tensors()\n",
    "evaluate_model(interpreter_int_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a694238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:42:02.570888Z",
     "iopub.status.busy": "2022-07-02T09:42:02.570509Z",
     "iopub.status.idle": "2022-07-02T09:42:04.147249Z",
     "shell.execute_reply": "2022-07-02T09:42:04.145966Z"
    },
    "papermill": {
     "duration": 1.634138,
     "end_time": "2022-07-02T09:42:04.149409",
     "exception": false,
     "start_time": "2022-07-02T09:42:02.515271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_float16_quant = tf.lite.Interpreter(model_path=str(tflite_float16_quant_model_file))\n",
    "interpreter_float16_quant.allocate_tensors()\n",
    "evaluate_model(interpreter_float16_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70559373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T09:42:04.260153Z",
     "iopub.status.busy": "2022-07-02T09:42:04.259782Z",
     "iopub.status.idle": "2022-07-02T09:42:05.859482Z",
     "shell.execute_reply": "2022-07-02T09:42:05.858404Z"
    },
    "papermill": {
     "duration": 1.658147,
     "end_time": "2022-07-02T09:42:05.862144",
     "exception": false,
     "start_time": "2022-07-02T09:42:04.203997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_16x8_quant = tf.lite.Interpreter(model_path=str(tflite_16x8_quant_model_file))\n",
    "interpreter_16x8_quant.allocate_tensors()\n",
    "evaluate_model(interpreter_16x8_quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.68471,
   "end_time": "2022-07-02T09:42:09.500919",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-02T09:40:46.816209",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
