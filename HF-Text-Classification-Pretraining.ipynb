{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, re\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nfrom transformers import RobertaTokenizer, RobertaConfig, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom tokenizers import ByteLevelBPETokenizer\npd.options.display.max_columns = 30","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-30T13:18:20.844130Z","iopub.execute_input":"2022-06-30T13:18:20.844546Z","iopub.status.idle":"2022-06-30T13:18:29.341149Z","shell.execute_reply.started":"2022-06-30T13:18:20.844462Z","shell.execute_reply":"2022-06-30T13:18:29.340142Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Get the Data","metadata":{}},{"cell_type":"code","source":"x_train, y_train = fetch_20newsgroups(subset='train', return_X_y=True)\nx_valid, y_valid = fetch_20newsgroups(subset='test', return_X_y=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:29.343566Z","iopub.execute_input":"2022-06-30T13:18:29.344570Z","iopub.status.idle":"2022-06-30T13:18:39.336133Z","shell.execute_reply.started":"2022-06-30T13:18:29.344531Z","shell.execute_reply":"2022-06-30T13:18:39.335155Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Building Tokenizer","metadata":{}},{"cell_type":"code","source":"os.mkdir('text_files')\nfor e, text in enumerate(x_train):\n    with open(f\"text_files/train_{e+1:05}.txt\", 'w') as f:\n        f.write(re.sub(r'\\s+', ' ', text))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:39.337467Z","iopub.execute_input":"2022-06-30T13:18:39.338058Z","iopub.status.idle":"2022-06-30T13:18:42.238267Z","shell.execute_reply.started":"2022-06-30T13:18:39.338022Z","shell.execute_reply":"2022-06-30T13:18:42.237269Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = ByteLevelBPETokenizer()\ntokenizer.train(\n    files=[f\"text_files/train_{e+1:05}.txt\" for e in range(len(x_train))], vocab_size=30_522,\n    special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>']\n)\nos.mkdir('newsbert')\ntokenizer.save_model('newsbert')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:42.241117Z","iopub.execute_input":"2022-06-30T13:18:42.241491Z","iopub.status.idle":"2022-06-30T13:18:56.069732Z","shell.execute_reply.started":"2022-06-30T13:18:42.241455Z","shell.execute_reply":"2022-06-30T13:18:56.068782Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['newsbert/vocab.json', 'newsbert/merges.txt']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained('newsbert', max_len=1024)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:56.070991Z","iopub.execute_input":"2022-06-30T13:18:56.071850Z","iopub.status.idle":"2022-06-30T13:18:56.137437Z","shell.execute_reply.started":"2022-06-30T13:18:56.071809Z","shell.execute_reply":"2022-06-30T13:18:56.136435Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'BertTokenizer'. \nThe class this function is called from is 'RobertaTokenizer'.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tokenize Data","metadata":{}},{"cell_type":"code","source":"def tokenize(texts):\n    return tokenizer(\n        texts, padding='max_length', truncation=True, max_length=1024, return_tensors='pt'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:56.139353Z","iopub.execute_input":"2022-06-30T13:18:56.139722Z","iopub.status.idle":"2022-06-30T13:18:56.145530Z","shell.execute_reply.started":"2022-06-30T13:18:56.139685Z","shell.execute_reply":"2022-06-30T13:18:56.144277Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x_train_tokenized = tokenize(x_train)\nx_valid_tokenized = tokenize(x_valid)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:18:56.147320Z","iopub.execute_input":"2022-06-30T13:18:56.147710Z","iopub.status.idle":"2022-06-30T13:20:31.696370Z","shell.execute_reply.started":"2022-06-30T13:18:56.147674Z","shell.execute_reply":"2022-06-30T13:20:31.695388Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data Loaders","metadata":{}},{"cell_type":"code","source":"class TextClassificationDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = TextClassificationDataset(x_train_tokenized, y_train)\nvalid_dataset = TextClassificationDataset(x_valid_tokenized, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:20:31.697991Z","iopub.execute_input":"2022-06-30T13:20:31.698364Z","iopub.status.idle":"2022-06-30T13:20:31.707472Z","shell.execute_reply.started":"2022-06-30T13:20:31.698327Z","shell.execute_reply":"2022-06-30T13:20:31.706523Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Building Model","metadata":{}},{"cell_type":"code","source":"config = RobertaConfig(\n    vocab_size=30_522,\n    max_position_embeddings=1026,\n    hidden_size=768,\n    num_attention_heads=12,\n    num_hidden_layers=6,\n    type_vocab_size=1, \n    num_labels=20,\n)\nmodel = RobertaForSequenceClassification(config)\ntraining_args = TrainingArguments(\"news_classifier\", num_train_epochs=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:20:31.709231Z","iopub.execute_input":"2022-06-30T13:20:31.709669Z","iopub.status.idle":"2022-06-30T13:20:33.398836Z","shell.execute_reply.started":"2022-06-30T13:20:31.709632Z","shell.execute_reply":"2022-06-30T13:20:33.397707Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:20:33.403577Z","iopub.execute_input":"2022-06-30T13:20:33.405126Z","iopub.status.idle":"2022-06-30T13:45:00.185352Z","shell.execute_reply.started":"2022-06-30T13:20:33.405088Z","shell.execute_reply":"2022-06-30T13:45:00.181848Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 11314\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2830\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.20 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.18"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220630_132051-3in647hi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/ritvik19/huggingface/runs/3in647hi\" target=\"_blank\">news_classifier</a></strong> to <a href=\"https://wandb.ai/ritvik19/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2830' max='2830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2830/2830 24:04, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.057400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.951800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.399000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.066400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.005900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to news_classifier/checkpoint-500\nConfiguration saved in news_classifier/checkpoint-500/config.json\nModel weights saved in news_classifier/checkpoint-500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\nSaving model checkpoint to news_classifier/checkpoint-1000\nConfiguration saved in news_classifier/checkpoint-1000/config.json\nModel weights saved in news_classifier/checkpoint-1000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\nSaving model checkpoint to news_classifier/checkpoint-1500\nConfiguration saved in news_classifier/checkpoint-1500/config.json\nModel weights saved in news_classifier/checkpoint-1500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\nSaving model checkpoint to news_classifier/checkpoint-2000\nConfiguration saved in news_classifier/checkpoint-2000/config.json\nModel weights saved in news_classifier/checkpoint-2000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\nSaving model checkpoint to news_classifier/checkpoint-2500\nConfiguration saved in news_classifier/checkpoint-2500/config.json\nModel weights saved in news_classifier/checkpoint-2500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2830, training_loss=2.429375293313825, metrics={'train_runtime': 1460.6347, 'train_samples_per_second': 15.492, 'train_steps_per_second': 1.938, 'total_flos': 5996868997447680.0, 'train_loss': 2.429375293313825, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"model_checkpoint = 'news_classifier/checkpoint-2500/'\nmodel = RobertaForSequenceClassification.from_pretrained(model_checkpoint, num_labels=20)\ntrainer = Trainer(\n    model,\n    training_args\n)\npredictions = trainer.predict(valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:45:00.187223Z","iopub.execute_input":"2022-06-30T13:45:00.188588Z","iopub.status.idle":"2022-06-30T13:47:38.420819Z","shell.execute_reply.started":"2022-06-30T13:45:00.188528Z","shell.execute_reply":"2022-06-30T13:47:38.419902Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"loading configuration file news_classifier/checkpoint-2500/config.json\nModel config RobertaConfig {\n  \"architectures\": [\n    \"RobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\",\n    \"5\": \"LABEL_5\",\n    \"6\": \"LABEL_6\",\n    \"7\": \"LABEL_7\",\n    \"8\": \"LABEL_8\",\n    \"9\": \"LABEL_9\",\n    \"10\": \"LABEL_10\",\n    \"11\": \"LABEL_11\",\n    \"12\": \"LABEL_12\",\n    \"13\": \"LABEL_13\",\n    \"14\": \"LABEL_14\",\n    \"15\": \"LABEL_15\",\n    \"16\": \"LABEL_16\",\n    \"17\": \"LABEL_17\",\n    \"18\": \"LABEL_18\",\n    \"19\": \"LABEL_19\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_10\": 10,\n    \"LABEL_11\": 11,\n    \"LABEL_12\": 12,\n    \"LABEL_13\": 13,\n    \"LABEL_14\": 14,\n    \"LABEL_15\": 15,\n    \"LABEL_16\": 16,\n    \"LABEL_17\": 17,\n    \"LABEL_18\": 18,\n    \"LABEL_19\": 19,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3,\n    \"LABEL_4\": 4,\n    \"LABEL_5\": 5,\n    \"LABEL_6\": 6,\n    \"LABEL_7\": 7,\n    \"LABEL_8\": 8,\n    \"LABEL_9\": 9\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 1026,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file news_classifier/checkpoint-2500/pytorch_model.bin\nAll model checkpoint weights were used when initializing RobertaForSequenceClassification.\n\nAll the weights of RobertaForSequenceClassification were initialized from the model checkpoint at news_classifier/checkpoint-2500/.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n***** Running Prediction *****\n  Num examples = 7532\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [942/942 02:36]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"clf_report = pd.DataFrame(confusion_matrix(y_valid, predictions.label_ids))\nprecision, recall, fscore, support = precision_recall_fscore_support(y_valid, predictions.label_ids)\nclf_report['precision'] = precision\nclf_report['recall'] = recall\nclf_report['fscore'] = fscore\nclf_report['support'] = support\nclf_report\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:47:38.422789Z","iopub.execute_input":"2022-06-30T13:47:38.423392Z","iopub.status.idle":"2022-06-30T13:47:38.494048Z","shell.execute_reply.started":"2022-06-30T13:47:38.423354Z","shell.execute_reply":"2022-06-30T13:47:38.492933Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n0   319    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n1     0  389    0    0    0    0    0    0    0    0    0    0    0    0    0   \n2     0    0  394    0    0    0    0    0    0    0    0    0    0    0    0   \n3     0    0    0  392    0    0    0    0    0    0    0    0    0    0    0   \n4     0    0    0    0  385    0    0    0    0    0    0    0    0    0    0   \n5     0    0    0    0    0  395    0    0    0    0    0    0    0    0    0   \n6     0    0    0    0    0    0  390    0    0    0    0    0    0    0    0   \n7     0    0    0    0    0    0    0  396    0    0    0    0    0    0    0   \n8     0    0    0    0    0    0    0    0  398    0    0    0    0    0    0   \n9     0    0    0    0    0    0    0    0    0  397    0    0    0    0    0   \n10    0    0    0    0    0    0    0    0    0    0  399    0    0    0    0   \n11    0    0    0    0    0    0    0    0    0    0    0  396    0    0    0   \n12    0    0    0    0    0    0    0    0    0    0    0    0  393    0    0   \n13    0    0    0    0    0    0    0    0    0    0    0    0    0  396    0   \n14    0    0    0    0    0    0    0    0    0    0    0    0    0    0  394   \n15    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n17    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n19    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n\n     15   16   17   18   19  precision  recall  fscore  support  \n0     0    0    0    0    0        1.0     1.0     1.0      319  \n1     0    0    0    0    0        1.0     1.0     1.0      389  \n2     0    0    0    0    0        1.0     1.0     1.0      394  \n3     0    0    0    0    0        1.0     1.0     1.0      392  \n4     0    0    0    0    0        1.0     1.0     1.0      385  \n5     0    0    0    0    0        1.0     1.0     1.0      395  \n6     0    0    0    0    0        1.0     1.0     1.0      390  \n7     0    0    0    0    0        1.0     1.0     1.0      396  \n8     0    0    0    0    0        1.0     1.0     1.0      398  \n9     0    0    0    0    0        1.0     1.0     1.0      397  \n10    0    0    0    0    0        1.0     1.0     1.0      399  \n11    0    0    0    0    0        1.0     1.0     1.0      396  \n12    0    0    0    0    0        1.0     1.0     1.0      393  \n13    0    0    0    0    0        1.0     1.0     1.0      396  \n14    0    0    0    0    0        1.0     1.0     1.0      394  \n15  398    0    0    0    0        1.0     1.0     1.0      398  \n16    0  364    0    0    0        1.0     1.0     1.0      364  \n17    0    0  376    0    0        1.0     1.0     1.0      376  \n18    0    0    0  310    0        1.0     1.0     1.0      310  \n19    0    0    0    0  251        1.0     1.0     1.0      251  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>fscore</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>319</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>319</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>389</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>389</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>394</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>394</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>392</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>392</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>385</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>385</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>395</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>390</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>390</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>396</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>396</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>398</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>398</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>397</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>399</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>399</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>396</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>396</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>393</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>393</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>396</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>396</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>394</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>394</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>398</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>398</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>364</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>364</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>376</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>376</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>310</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>310</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>251</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>251</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}