{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d2bb25",
   "metadata": {
    "papermill": {
     "duration": 0.01697,
     "end_time": "2022-01-22T12:32:20.055836",
     "exception": false,
     "start_time": "2022-01-22T12:32:20.038866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TabNet\n",
    "\n",
    "TabNet (introduced [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf)) is a novel high-performance and interpretable canonical deep tabular data learning architecture. It uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc920dcb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:20.109652Z",
     "iopub.status.busy": "2022-01-22T12:32:20.108949Z",
     "iopub.status.idle": "2022-01-22T12:32:26.435675Z",
     "shell.execute_reply": "2022-01-22T12:32:26.436260Z",
     "shell.execute_reply.started": "2022-01-22T11:52:54.383548Z"
    },
    "papermill": {
     "duration": 6.359237,
     "end_time": "2022-01-22T12:32:26.436550",
     "exception": false,
     "start_time": "2022-01-22T12:32:20.077313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow_addons.activations import sparsemax\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384823b6",
   "metadata": {
    "papermill": {
     "duration": 0.013786,
     "end_time": "2022-01-22T12:32:26.464565",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.450779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a51e4d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:26.495993Z",
     "iopub.status.busy": "2022-01-22T12:32:26.495380Z",
     "iopub.status.idle": "2022-01-22T12:32:26.736425Z",
     "shell.execute_reply": "2022-01-22T12:32:26.736931Z",
     "shell.execute_reply.started": "2022-01-22T11:52:54.392636Z"
    },
    "papermill": {
     "duration": 0.258629,
     "end_time": "2022-01-22T12:32:26.737127",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.478498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>audio_mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>audio_valence</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>212990.0</td>\n",
       "      <td>0.642286</td>\n",
       "      <td>0.856520</td>\n",
       "      <td>0.707073</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.619088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082570</td>\n",
       "      <td>158.386236</td>\n",
       "      <td>4</td>\n",
       "      <td>0.734642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054866</td>\n",
       "      <td>0.733289</td>\n",
       "      <td>0.835545</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.436428</td>\n",
       "      <td>-5.236965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127358</td>\n",
       "      <td>102.752988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.711531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>193213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.188387</td>\n",
       "      <td>0.783524</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.170499</td>\n",
       "      <td>-4.951759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052282</td>\n",
       "      <td>178.685791</td>\n",
       "      <td>3</td>\n",
       "      <td>0.425536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>249893.0</td>\n",
       "      <td>0.488660</td>\n",
       "      <td>0.585234</td>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094805</td>\n",
       "      <td>-7.893694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035618</td>\n",
       "      <td>128.715630</td>\n",
       "      <td>3</td>\n",
       "      <td>0.453597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>165969.0</td>\n",
       "      <td>0.493017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740982</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>-2.684095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>121.928157</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  song_duration_ms  acousticness  danceability    energy  \\\n",
       "0   0          212990.0      0.642286      0.856520  0.707073   \n",
       "1   1               NaN      0.054866      0.733289  0.835545   \n",
       "2   2          193213.0           NaN      0.188387  0.783524   \n",
       "3   3          249893.0      0.488660      0.585234  0.552685   \n",
       "4   4          165969.0      0.493017           NaN  0.740982   \n",
       "\n",
       "   instrumentalness   key  liveness  loudness  audio_mode  speechiness  \\\n",
       "0          0.002001  10.0       NaN -5.619088           0     0.082570   \n",
       "1          0.000996   8.0  0.436428 -5.236965           1     0.127358   \n",
       "2         -0.002694   5.0  0.170499 -4.951759           0     0.052282   \n",
       "3          0.000608   0.0  0.094805 -7.893694           0     0.035618   \n",
       "4          0.002033  10.0  0.094891 -2.684095           0     0.050746   \n",
       "\n",
       "        tempo  time_signature  audio_valence  song_popularity  \n",
       "0  158.386236               4       0.734642                0  \n",
       "1  102.752988               3       0.711531                1  \n",
       "2  178.685791               3       0.425536                0  \n",
       "3  128.715630               3       0.453597                0  \n",
       "4  121.928157               4       0.741311                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../input/song-popularity-prediction/train.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4869ecfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:26.771517Z",
     "iopub.status.busy": "2022-01-22T12:32:26.770566Z",
     "iopub.status.idle": "2022-01-22T12:32:26.832187Z",
     "shell.execute_reply": "2022-01-22T12:32:26.831603Z",
     "shell.execute_reply.started": "2022-01-22T11:52:54.594538Z"
    },
    "papermill": {
     "duration": 0.079559,
     "end_time": "2022-01-22T12:32:26.832348",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.752789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/song-popularity-prediction/test.csv')\n",
    "X_test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35be9b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:26.871830Z",
     "iopub.status.busy": "2022-01-22T12:32:26.870858Z",
     "iopub.status.idle": "2022-01-22T12:32:26.876048Z",
     "shell.execute_reply": "2022-01-22T12:32:26.876950Z",
     "shell.execute_reply.started": "2022-01-22T11:52:54.622992Z"
    },
    "papermill": {
     "duration": 0.029314,
     "end_time": "2022-01-22T12:32:26.877175",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.847861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(['id', 'song_popularity'], axis=1)\n",
    "y = data[['song_popularity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89691e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:26.920983Z",
     "iopub.status.busy": "2022-01-22T12:32:26.920034Z",
     "iopub.status.idle": "2022-01-22T12:32:26.922305Z",
     "shell.execute_reply": "2022-01-22T12:32:26.922924Z",
     "shell.execute_reply.started": "2022-01-22T11:52:54.633798Z"
    },
    "papermill": {
     "duration": 0.025278,
     "end_time": "2022-01-22T12:32:26.923125",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.897847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe7c9f",
   "metadata": {
    "papermill": {
     "duration": 0.014167,
     "end_time": "2022-01-22T12:32:26.952389",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.938222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec58d67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:26.990823Z",
     "iopub.status.busy": "2022-01-22T12:32:26.989775Z",
     "iopub.status.idle": "2022-01-22T12:32:27.003262Z",
     "shell.execute_reply": "2022-01-22T12:32:27.003746Z",
     "shell.execute_reply.started": "2022-01-22T11:53:24.078683Z"
    },
    "papermill": {
     "duration": 0.036949,
     "end_time": "2022-01-22T12:32:27.003888",
     "exception": false,
     "start_time": "2022-01-22T12:32:26.966939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def register_keras_custom_object(cls):\n",
    "    tf.keras.utils.get_custom_objects()[cls.__name__] = cls\n",
    "    return cls\n",
    "\n",
    "\n",
    "def glu(x, n_units=None):\n",
    "    if n_units is None:\n",
    "        n_units = tf.shape(x)[-1] // 2\n",
    "\n",
    "    return x[..., :n_units] * tf.nn.sigmoid(x[..., n_units:])\n",
    "\n",
    "\n",
    "@register_keras_custom_object\n",
    "@tf.function\n",
    "def sparsemax(logits, axis):\n",
    "    logits = tf.convert_to_tensor(logits, name=\"logits\")\n",
    "\n",
    "    shape = logits.get_shape()\n",
    "    rank = shape.rank\n",
    "    is_last_axis = (axis == -1) or (axis == rank - 1)\n",
    "\n",
    "    if is_last_axis:\n",
    "        output = _compute_2d_sparsemax(logits)\n",
    "        output.set_shape(shape)\n",
    "        return output\n",
    "\n",
    "    rank_op = tf.rank(logits)\n",
    "    axis_norm = axis % rank\n",
    "    logits = _swap_axis(logits, axis_norm, tf.math.subtract(rank_op, 1))\n",
    "\n",
    "    output = _compute_2d_sparsemax(logits)\n",
    "    output = _swap_axis(output, axis_norm, tf.math.subtract(rank_op, 1))\n",
    "\n",
    "    output.set_shape(shape)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _swap_axis(logits, dim_index, last_index, **kwargs):\n",
    "    return tf.transpose(\n",
    "        logits,\n",
    "        tf.concat(\n",
    "            [\n",
    "                tf.range(dim_index),\n",
    "                [last_index],\n",
    "                tf.range(dim_index + 1, last_index),\n",
    "                [dim_index],\n",
    "            ],\n",
    "            0,\n",
    "        ),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def _compute_2d_sparsemax(logits):\n",
    "    shape_op = tf.shape(logits)\n",
    "    obs = tf.math.reduce_prod(shape_op[:-1])\n",
    "    dims = shape_op[-1]\n",
    "    z = tf.reshape(logits, [obs, dims])\n",
    "    z_sorted, _ = tf.nn.top_k(z, k=dims)\n",
    "    z_cumsum = tf.math.cumsum(z_sorted, axis=-1)\n",
    "    k = tf.range(1, tf.cast(dims, logits.dtype) + 1, dtype=logits.dtype)\n",
    "    z_check = 1 + k * z_sorted > z_cumsum\n",
    "    k_z = tf.math.reduce_sum(tf.cast(z_check, tf.int32), axis=-1)\n",
    "    k_z_safe = tf.math.maximum(k_z, 1)\n",
    "    indices = tf.stack([tf.range(0, obs), tf.reshape(k_z_safe, [-1]) - 1], axis=1)\n",
    "    tau_sum = tf.gather_nd(z_cumsum, indices)\n",
    "    tau_z = (tau_sum - 1) / tf.cast(k_z, logits.dtype)\n",
    "    p = tf.math.maximum(tf.cast(0, logits.dtype), z - tf.expand_dims(tau_z, -1))\n",
    "    p_safe = tf.where(\n",
    "        tf.expand_dims(\n",
    "            tf.math.logical_or(tf.math.equal(k_z, 0), tf.math.is_nan(z_cumsum[:, -1])),\n",
    "            axis=-1,\n",
    "        ),\n",
    "        tf.fill([obs, dims], tf.cast(float(\"nan\"), logits.dtype)),\n",
    "        p,\n",
    "    )\n",
    "    p_safe = tf.reshape(p_safe, shape_op)\n",
    "    return p_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36127505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:27.036414Z",
     "iopub.status.busy": "2022-01-22T12:32:27.035483Z",
     "iopub.status.idle": "2022-01-22T12:32:27.042940Z",
     "shell.execute_reply": "2022-01-22T12:32:27.043506Z",
     "shell.execute_reply.started": "2022-01-22T11:53:24.583867Z"
    },
    "papermill": {
     "duration": 0.025364,
     "end_time": "2022-01-22T12:32:27.043650",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.018286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformBlock(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self, features, momentum=0.9, virtual_batch_size=None, block_name='', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features = features\n",
    "        self.momentum = momentum\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "\n",
    "        self.transform = tf.keras.layers.Dense(self.features, use_bias=False, name=f'transformblock_dense_{block_name}')\n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            axis=-1, momentum=momentum, virtual_batch_size=virtual_batch_size, name=f'transformblock_bn_{block_name}'\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.transform(inputs)\n",
    "        x = self.bn(x, training=training)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d3fe15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:27.077509Z",
     "iopub.status.busy": "2022-01-22T12:32:27.076363Z",
     "iopub.status.idle": "2022-01-22T12:32:27.123547Z",
     "shell.execute_reply": "2022-01-22T12:32:27.124047Z",
     "shell.execute_reply.started": "2022-01-22T11:53:25.067287Z"
    },
    "papermill": {
     "duration": 0.065749,
     "end_time": "2022-01-22T12:32:27.124202",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.058453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabNet(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_columns, \n",
    "        feature_dim=64,\n",
    "        output_dim=64,\n",
    "        num_features=None,\n",
    "        num_decision_steps=5,\n",
    "        relaxation_factor=1.5,\n",
    "        sparsity_coefficient=1e-5,\n",
    "        batch_momentum=0.98,\n",
    "        virtual_batch_size=None,\n",
    "        epsilon=1e-5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(TabNet, self).__init__(**kwargs)\n",
    "\n",
    "        if feature_columns is not None:\n",
    "            if type(feature_columns) not in (list, tuple):\n",
    "                raise ValueError(\"`feature_columns` must be a list or a tuple.\")\n",
    "\n",
    "            if len(feature_columns) == 0:\n",
    "                raise ValueError(\"`feature_columns` must be contain at least 1 tf.feature_column !\")\n",
    "\n",
    "            if num_features is None:\n",
    "                num_features = len(feature_columns)\n",
    "            else:\n",
    "                num_features = int(num_features)\n",
    "\n",
    "        else:\n",
    "            if num_features is None:\n",
    "                raise ValueError(\"If `feature_columns` is None, then `num_features` cannot be None.\")\n",
    "\n",
    "        if num_decision_steps < 1:\n",
    "            raise ValueError(\"Num decision steps must be greater than 0.\")\n",
    "\n",
    "        if feature_dim <= output_dim:\n",
    "            raise ValueError(\"To compute `features_for_coef`, feature_dim must be larger than output dim\")\n",
    "\n",
    "        feature_dim = int(feature_dim)\n",
    "        output_dim = int(output_dim)\n",
    "        num_decision_steps = int(num_decision_steps)\n",
    "        relaxation_factor = float(relaxation_factor)\n",
    "        sparsity_coefficient = float(sparsity_coefficient)\n",
    "        batch_momentum = float(batch_momentum)\n",
    "        epsilon = float(epsilon)\n",
    "\n",
    "        if relaxation_factor < 0.:\n",
    "            raise ValueError(\"`relaxation_factor` cannot be negative !\")\n",
    "\n",
    "        if sparsity_coefficient < 0.:\n",
    "            raise ValueError(\"`sparsity_coefficient` cannot be negative !\")\n",
    "\n",
    "        if virtual_batch_size is not None:\n",
    "            virtual_batch_size = int(virtual_batch_size)\n",
    "\n",
    "        self.feature_columns = feature_columns\n",
    "        self.num_features = num_features\n",
    "        self.feature_dim = feature_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.num_decision_steps = num_decision_steps\n",
    "        self.relaxation_factor = relaxation_factor\n",
    "        self.sparsity_coefficient = sparsity_coefficient\n",
    "        self.batch_momentum = batch_momentum\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        if num_decision_steps > 1:\n",
    "            features_for_coeff = feature_dim - output_dim\n",
    "            print(f\"[TabNet]: {features_for_coeff} features will be used for decision steps.\")\n",
    "\n",
    "        if self.feature_columns is not None:\n",
    "            self.input_features = tf.keras.layers.DenseFeatures(feature_columns, trainable=True)\n",
    "\n",
    "            self.input_bn = tf.keras.layers.BatchNormalization(axis=-1, momentum=batch_momentum, name='input_bn')\n",
    "            \n",
    "        else:\n",
    "            self.input_features = None\n",
    "            self.input_bn = None\n",
    "\n",
    "        self.transform_f1 = TransformBlock(\n",
    "            2 * self.feature_dim,self.batch_momentum, self.virtual_batch_size, block_name='f1'\n",
    "        )\n",
    "\n",
    "        self.transform_f2 = TransformBlock(\n",
    "            2 * self.feature_dim, self.batch_momentum, self.virtual_batch_size, block_name='f2'\n",
    "        )\n",
    "\n",
    "        self.transform_f3_list = [\n",
    "            TransformBlock(2 * self.feature_dim, self.batch_momentum, self.virtual_batch_size, block_name=f'f3_{i}')\n",
    "            for i in range(self.num_decision_steps)\n",
    "        ]\n",
    "\n",
    "        self.transform_f4_list = [\n",
    "            TransformBlock(2 * self.feature_dim, self.batch_momentum, self.virtual_batch_size, block_name=f'f4_{i}')\n",
    "            for i in range(self.num_decision_steps)\n",
    "        ]\n",
    "\n",
    "        self.transform_coef_list = [\n",
    "            TransformBlock(self.num_features, self.batch_momentum, self.virtual_batch_size, block_name=f'coef_{i}')\n",
    "            for i in range(self.num_decision_steps - 1)\n",
    "        ]\n",
    "\n",
    "        self._step_feature_selection_masks = None\n",
    "        self._step_aggregate_feature_selection_mask = None\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if self.input_features is not None:\n",
    "            features = self.input_features(inputs)\n",
    "            features = self.input_bn(features, training=training)\n",
    "\n",
    "        else:\n",
    "            features = inputs\n",
    "\n",
    "        batch_size = tf.shape(features)[0]\n",
    "        self._step_feature_selection_masks = []\n",
    "        self._step_aggregate_feature_selection_mask = None\n",
    "\n",
    "        output_aggregated = tf.zeros([batch_size, self.output_dim])\n",
    "        masked_features = features\n",
    "        mask_values = tf.zeros([batch_size, self.num_features])\n",
    "        aggregated_mask_values = tf.zeros([batch_size, self.num_features])\n",
    "        complementary_aggregated_mask_values = tf.ones(\n",
    "            [batch_size, self.num_features])\n",
    "\n",
    "        total_entropy = 0.0\n",
    "        entropy_loss = 0.\n",
    "\n",
    "        for ni in range(self.num_decision_steps):\n",
    "            transform_f1 = self.transform_f1(masked_features, training=training)\n",
    "            transform_f1 = glu(transform_f1, self.feature_dim)\n",
    "\n",
    "            transform_f2 = self.transform_f2(transform_f1, training=training)\n",
    "            transform_f2 = (glu(transform_f2, self.feature_dim) +\n",
    "                            transform_f1) * tf.math.sqrt(0.5)\n",
    "\n",
    "            transform_f3 = self.transform_f3_list[ni](transform_f2, training=training)\n",
    "            transform_f3 = (glu(transform_f3, self.feature_dim) +\n",
    "                            transform_f2) * tf.math.sqrt(0.5)\n",
    "\n",
    "            transform_f4 = self.transform_f4_list[ni](transform_f3, training=training)\n",
    "            transform_f4 = (glu(transform_f4, self.feature_dim) +\n",
    "                            transform_f3) * tf.math.sqrt(0.5)\n",
    "\n",
    "            if (ni > 0 or self.num_decision_steps == 1):\n",
    "                decision_out = tf.nn.relu(transform_f4[:, :self.output_dim])\n",
    "                output_aggregated += decision_out\n",
    "                scale_agg = tf.reduce_sum(decision_out, axis=1, keepdims=True)\n",
    "\n",
    "                if self.num_decision_steps > 1:\n",
    "                    scale_agg = scale_agg / tf.cast(self.num_decision_steps - 1, tf.float32)\n",
    "\n",
    "                aggregated_mask_values += mask_values * scale_agg\n",
    "\n",
    "            features_for_coef = transform_f4[:, self.output_dim:]\n",
    "\n",
    "            if ni < (self.num_decision_steps - 1):\n",
    "                mask_values = self.transform_coef_list[ni](features_for_coef, training=training)\n",
    "                mask_values *= complementary_aggregated_mask_values\n",
    "                mask_values = sparsemax(mask_values, axis=-1)\n",
    "\n",
    "                complementary_aggregated_mask_values *= (\n",
    "                        self.relaxation_factor - mask_values)\n",
    "                total_entropy += tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        -mask_values * tf.math.log(mask_values + self.epsilon), axis=1)) / (\n",
    "                                     tf.cast(self.num_decision_steps - 1, tf.float32))\n",
    "\n",
    "                entropy_loss = total_entropy\n",
    "\n",
    "                masked_features = tf.multiply(mask_values, features)\n",
    "\n",
    "                mask_at_step_i = tf.expand_dims(tf.expand_dims(mask_values, 0), 3)\n",
    "                self._step_feature_selection_masks.append(mask_at_step_i)\n",
    "\n",
    "            else:\n",
    "                entropy_loss = 0.\n",
    "\n",
    "        self.add_loss(self.sparsity_coefficient * entropy_loss)\n",
    "\n",
    "        agg_mask = tf.expand_dims(tf.expand_dims(aggregated_mask_values, 0), 3)\n",
    "        self._step_aggregate_feature_selection_mask = agg_mask\n",
    "\n",
    "        return output_aggregated\n",
    "\n",
    "    @property\n",
    "    def feature_selection_masks(self):\n",
    "        return self._step_feature_selection_masks\n",
    "\n",
    "    @property\n",
    "    def aggregate_feature_selection_mask(self):\n",
    "        return self._step_aggregate_feature_selection_mask\n",
    "\n",
    "\n",
    "class TabNetClassifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_columns,\n",
    "        num_classes,\n",
    "        num_features=None,\n",
    "        feature_dim=64,\n",
    "        output_dim=64,\n",
    "        num_decision_steps=5,\n",
    "        relaxation_factor=1.5,\n",
    "        sparsity_coefficient=1e-5,\n",
    "        batch_momentum=0.98,\n",
    "        virtual_batch_size=None,\n",
    "        epsilon=1e-5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.tabnet = TabNet(\n",
    "            feature_columns=feature_columns,\n",
    "            num_features=num_features,\n",
    "            feature_dim=feature_dim,\n",
    "            output_dim=output_dim,\n",
    "            num_decision_steps=num_decision_steps,\n",
    "            relaxation_factor=relaxation_factor,\n",
    "            sparsity_coefficient=sparsity_coefficient,\n",
    "            batch_momentum=batch_momentum,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            epsilon=epsilon,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.clf = tf.keras.layers.Dense(num_classes, activation='softmax', use_bias=False, name='classifier')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        self.activations = self.tabnet(inputs, training=training)\n",
    "        out = self.clf(self.activations)\n",
    "        return out\n",
    "\n",
    "    def summary(self, *super_args, **super_kwargs):\n",
    "        super().summary(*super_args, **super_kwargs)\n",
    "        self.tabnet.summary(*super_args, **super_kwargs)\n",
    "\n",
    "\n",
    "class TabNetRegressor(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_columns,\n",
    "        num_regressors,\n",
    "        num_features=None,\n",
    "        feature_dim=64,\n",
    "        output_dim=64,\n",
    "        num_decision_steps=5,\n",
    "        relaxation_factor=1.5,\n",
    "        sparsity_coefficient=1e-5,\n",
    "        batch_momentum=0.98,\n",
    "        virtual_batch_size=None,\n",
    "        epsilon=1e-5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_regressors = num_regressors\n",
    "        self.tabnet = TabNet(\n",
    "            feature_columns=feature_columns,\n",
    "            num_features=num_features,\n",
    "            feature_dim=feature_dim,\n",
    "            output_dim=output_dim,\n",
    "            num_decision_steps=num_decision_steps,\n",
    "            relaxation_factor=relaxation_factor,\n",
    "            sparsity_coefficient=sparsity_coefficient,\n",
    "            batch_momentum=batch_momentum,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            epsilon=epsilon,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = tf.keras.layers.Dense(num_regressors, use_bias=False, name='regressor')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        self.activations = self.tabnet(inputs, training=training)\n",
    "        out = self.regressor(self.activations)\n",
    "        return out\n",
    "\n",
    "    def summary(self, *super_args, **super_kwargs):\n",
    "        super().summary(*super_args, **super_kwargs)\n",
    "        self.tabnet.summary(*super_args, **super_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019fc361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:27.157198Z",
     "iopub.status.busy": "2022-01-22T12:32:27.156590Z",
     "iopub.status.idle": "2022-01-22T12:32:27.160433Z",
     "shell.execute_reply": "2022-01-22T12:32:27.160937Z",
     "shell.execute_reply.started": "2022-01-22T11:53:25.514527Z"
    },
    "papermill": {
     "duration": 0.021759,
     "end_time": "2022-01-22T12:32:27.161103",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.139344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_cat_pipeline = lambda: Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "get_num_pipeline = lambda: Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), \n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "036c33c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:27.196507Z",
     "iopub.status.busy": "2022-01-22T12:32:27.195860Z",
     "iopub.status.idle": "2022-01-22T12:32:27.198084Z",
     "shell.execute_reply": "2022-01-22T12:32:27.197506Z",
     "shell.execute_reply.started": "2022-01-22T11:53:25.941818Z"
    },
    "papermill": {
     "duration": 0.022517,
     "end_time": "2022-01-22T12:32:27.198204",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.175687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    NUMERIC_FEATURE_NAMES=[\n",
    "        'song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness',\n",
    "        'speechiness', 'tempo', 'audio_valence'\n",
    "    ]\n",
    "    CATEGORICAL_FEATURE_NAMES=[\n",
    "        'key','audio_mode','time_signature'   \n",
    "    ]\n",
    "\n",
    "MAX_EPOCHS  = 250\n",
    "\n",
    "get_callbacks = lambda : [\n",
    "    keras.callbacks.EarlyStopping(min_delta=1e-4, patience=10, verbose=1, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba2cc0",
   "metadata": {
    "papermill": {
     "duration": 0.014336,
     "end_time": "2022-01-22T12:32:27.227234",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.212898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63625b42",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-22T12:32:27.258945Z",
     "iopub.status.busy": "2022-01-22T12:32:27.258370Z",
     "iopub.status.idle": "2022-01-22T16:17:52.689073Z",
     "shell.execute_reply": "2022-01-22T16:17:52.689896Z",
     "shell.execute_reply.started": "2022-01-22T11:53:26.871273Z"
    },
    "papermill": {
     "duration": 13525.448578,
     "end_time": "2022-01-22T16:17:52.690247",
     "exception": false,
     "start_time": "2022-01-22T12:32:27.241669",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-01-22 12:32:27.439594: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-22 12:32:27.611868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabNet]: 4 features will be used for decision steps.\n",
      "Epoch 1/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6924 - accuracy: 0.6054 - val_loss: 0.6601 - val_accuracy: 0.6356\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6637 - accuracy: 0.6307 - val_loss: 0.6567 - val_accuracy: 0.6356\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 161s 160ms/step - loss: 0.6609 - accuracy: 0.6319 - val_loss: 0.6561 - val_accuracy: 0.6355\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6579 - accuracy: 0.6350 - val_loss: 0.6558 - val_accuracy: 0.6354\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6569 - accuracy: 0.6347 - val_loss: 0.6554 - val_accuracy: 0.6356\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6562 - accuracy: 0.6354 - val_loss: 0.6576 - val_accuracy: 0.6356\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6559 - accuracy: 0.6353 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6551 - accuracy: 0.6359 - val_loss: 0.6563 - val_accuracy: 0.6356\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6552 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6356\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6552 - accuracy: 0.6354 - val_loss: 0.6563 - val_accuracy: 0.6356\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6551 - accuracy: 0.6351 - val_loss: 0.6549 - val_accuracy: 0.6356\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.6549 - accuracy: 0.6354 - val_loss: 0.6549 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/250\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.6544 - accuracy: 0.6355 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 14/250\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.6547 - accuracy: 0.6355 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 15/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6542 - accuracy: 0.6356 - val_loss: 0.6547 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 16/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6540 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 17/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6543 - accuracy: 0.6355 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 18/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "[TabNet]: 4 features will be used for decision steps.\n",
      "Epoch 1/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6989 - accuracy: 0.5949 - val_loss: 0.6571 - val_accuracy: 0.6355\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.6616 - accuracy: 0.6321 - val_loss: 0.6546 - val_accuracy: 0.6356\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6580 - accuracy: 0.6343 - val_loss: 0.6559 - val_accuracy: 0.6356\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6578 - accuracy: 0.6342 - val_loss: 0.6559 - val_accuracy: 0.6356\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6572 - accuracy: 0.6354 - val_loss: 0.6558 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6562 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6356\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.6554 - accuracy: 0.6356 - val_loss: 0.6557 - val_accuracy: 0.6356\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6559 - accuracy: 0.6354 - val_loss: 0.6555 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6550 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6356\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6556 - accuracy: 0.6355 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6554 - accuracy: 0.6355 - val_loss: 0.6555 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.6547 - accuracy: 0.6354 - val_loss: 0.6555 - val_accuracy: 0.6356\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "[TabNet]: 4 features will be used for decision steps.\n",
      "Epoch 1/250\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.7050 - accuracy: 0.6045 - val_loss: 0.6594 - val_accuracy: 0.6356\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6665 - accuracy: 0.6258 - val_loss: 0.6567 - val_accuracy: 0.6355\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6610 - accuracy: 0.6308 - val_loss: 0.6557 - val_accuracy: 0.6356\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6599 - accuracy: 0.6331 - val_loss: 0.6572 - val_accuracy: 0.6356\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6576 - accuracy: 0.6344 - val_loss: 0.6551 - val_accuracy: 0.6356\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6567 - accuracy: 0.6348 - val_loss: 0.6566 - val_accuracy: 0.6355\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6567 - accuracy: 0.6349 - val_loss: 0.6557 - val_accuracy: 0.6355\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6565 - accuracy: 0.6348 - val_loss: 0.6550 - val_accuracy: 0.6356\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6562 - accuracy: 0.6352 - val_loss: 0.6565 - val_accuracy: 0.6356\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6562 - accuracy: 0.6359 - val_loss: 0.6552 - val_accuracy: 0.6356\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.6555 - accuracy: 0.6356 - val_loss: 0.6565 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 164s 163ms/step - loss: 0.6548 - accuracy: 0.6357 - val_loss: 0.6556 - val_accuracy: 0.6356\n",
      "Epoch 13/250\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.6554 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6356\n",
      "Epoch 14/250\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.6548 - accuracy: 0.6357 - val_loss: 0.6554 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6545 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Epoch 16/250\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.6547 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6356\n",
      "Epoch 17/250\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.6542 - accuracy: 0.6355 - val_loss: 0.6555 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/250\n",
      "1000/1000 [==============================] - 161s 162ms/step - loss: 0.6544 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6356\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "[TabNet]: 4 features will be used for decision steps.\n",
      "Epoch 1/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6820 - accuracy: 0.6129 - val_loss: 0.6616 - val_accuracy: 0.6355\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.6614 - accuracy: 0.6311 - val_loss: 0.6566 - val_accuracy: 0.6356\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.6584 - accuracy: 0.6344 - val_loss: 0.6554 - val_accuracy: 0.6356\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6567 - accuracy: 0.6343 - val_loss: 0.6552 - val_accuracy: 0.6356\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6556 - accuracy: 0.6348 - val_loss: 0.6558 - val_accuracy: 0.6356\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6550 - accuracy: 0.6354 - val_loss: 0.6557 - val_accuracy: 0.6356\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6553 - accuracy: 0.6348 - val_loss: 0.6554 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6547 - accuracy: 0.6357 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6548 - accuracy: 0.6355 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.6544 - accuracy: 0.6357 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.6547 - accuracy: 0.6355 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6547 - accuracy: 0.6357 - val_loss: 0.6552 - val_accuracy: 0.6356\n",
      "Epoch 13/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6356\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "[TabNet]: 4 features will be used for decision steps.\n",
      "Epoch 1/250\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.6788 - accuracy: 0.6173 - val_loss: 0.6596 - val_accuracy: 0.6355\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6612 - accuracy: 0.6321 - val_loss: 0.6568 - val_accuracy: 0.6355\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.6591 - accuracy: 0.6330 - val_loss: 0.6560 - val_accuracy: 0.6355\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 169s 170ms/step - loss: 0.6572 - accuracy: 0.6349 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6569 - accuracy: 0.6345 - val_loss: 0.6556 - val_accuracy: 0.6355\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.6566 - accuracy: 0.6353 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.6563 - accuracy: 0.6359 - val_loss: 0.6556 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.6555 - accuracy: 0.6353 - val_loss: 0.6553 - val_accuracy: 0.6355\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6545 - accuracy: 0.6355 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.6541 - accuracy: 0.6355 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.6548 - accuracy: 0.6357 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.6546 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6355\n",
      "Epoch 13/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6546 - accuracy: 0.6354 - val_loss: 0.6553 - val_accuracy: 0.6355\n",
      "Epoch 14/250\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6543 - accuracy: 0.6354 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/250\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 16/250\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.6551 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Epoch 17/250\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.6545 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/250\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.6539 - accuracy: 0.6355 - val_loss: 0.6554 - val_accuracy: 0.6355\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "    num_pipeline = get_num_pipeline().fit(X_train[model_config.NUMERIC_FEATURE_NAMES])\n",
    "    cat_pipeline = get_cat_pipeline().fit(X_train[model_config.CATEGORICAL_FEATURE_NAMES])\n",
    "    \n",
    "    X_train = np.hstack((\n",
    "        num_pipeline.transform(X_train[model_config.NUMERIC_FEATURE_NAMES]),\n",
    "        cat_pipeline.transform(X_train[model_config.CATEGORICAL_FEATURE_NAMES])\n",
    "    ))\n",
    "    X_valid = np.hstack((\n",
    "        num_pipeline.transform(X_valid[model_config.NUMERIC_FEATURE_NAMES]),\n",
    "        cat_pipeline.transform(X_valid[model_config.CATEGORICAL_FEATURE_NAMES])\n",
    "    ))\n",
    "    X_test_ = np.hstack((\n",
    "        num_pipeline.transform(X_test[model_config.NUMERIC_FEATURE_NAMES]),\n",
    "        cat_pipeline.transform(X_test[model_config.CATEGORICAL_FEATURE_NAMES])\n",
    "    ))\n",
    "    \n",
    "    model = TabNetClassifier(\n",
    "        feature_columns=None, num_classes=2, num_features=X_train.shape[1], feature_dim=16, output_dim=12)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'], run_eagerly=True\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train, validation_data=(X_valid, y_valid), callbacks=get_callbacks(), \n",
    "        epochs=MAX_EPOCHS\n",
    "    )  \n",
    "    preds.append(model.predict(X_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51145378",
   "metadata": {
    "papermill": {
     "duration": 24.844612,
     "end_time": "2022-01-22T16:18:42.316662",
     "exception": false,
     "start_time": "2022-01-22T16:18:17.472050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77604a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T16:19:32.330700Z",
     "iopub.status.busy": "2022-01-22T16:19:32.329903Z",
     "iopub.status.idle": "2022-01-22T16:19:32.388836Z",
     "shell.execute_reply": "2022-01-22T16:19:32.388179Z",
     "shell.execute_reply.started": "2022-01-22T12:13:05.743261Z"
    },
    "papermill": {
     "duration": 24.860689,
     "end_time": "2022-01-22T16:19:32.388992",
     "exception": false,
     "start_time": "2022-01-22T16:19:07.528303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('../input/song-popularity-prediction/sample_submission.csv')\n",
    "submissions['song_popularity'] = np.array([arr[:, 1] for arr in preds]).mean(axis=0)\n",
    "submissions.to_csv('preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5617416",
   "metadata": {
    "papermill": {
     "duration": 24.89968,
     "end_time": "2022-01-22T16:20:22.047492",
     "exception": false,
     "start_time": "2022-01-22T16:19:57.147812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13719.205,
   "end_time": "2022-01-22T16:20:49.993989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-22T12:32:10.788989",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
