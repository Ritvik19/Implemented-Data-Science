{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-18T10:25:52.520446Z",
     "iopub.status.busy": "2021-12-18T10:25:52.52012Z",
     "iopub.status.idle": "2021-12-18T10:25:56.948991Z",
     "shell.execute_reply": "2021-12-18T10:25:56.948157Z",
     "shell.execute_reply.started": "2021-12-18T10:25:52.52037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:25:53.118143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:25:56.951187Z",
     "iopub.status.busy": "2021-12-18T10:25:56.95092Z",
     "iopub.status.idle": "2021-12-18T10:26:03.263098Z",
     "shell.execute_reply": "2021-12-18T10:26:03.262373Z",
     "shell.execute_reply.started": "2021-12-18T10:25:56.951153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255.0\n",
    "x_valid = x_valid/255.0\n",
    "# x_train = np.expand_dims(x_train, axis=3)\n",
    "# x_valid = np.expand_dims(x_valid, axis=3)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_valid = keras.utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.26476Z",
     "iopub.status.busy": "2021-12-18T10:26:03.26451Z",
     "iopub.status.idle": "2021-12-18T10:26:03.273839Z",
     "shell.execute_reply": "2021-12-18T10:26:03.273204Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.264728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3), 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_EPOCHS = 25\n",
    "S_EPOCHS = 20\n",
    "IMAGE_SIZE = x_train.shape[1:]\n",
    "BATCH_SIZE = 512\n",
    "N_CLASSES = y_train.shape[-1]\n",
    "IMAGE_SIZE, N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.275635Z",
     "iopub.status.busy": "2021-12-18T10:26:03.275174Z",
     "iopub.status.idle": "2021-12-18T10:26:03.28714Z",
     "shell.execute_reply": "2021-12-18T10:26:03.286353Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.275603Z"
    }
   },
   "outputs": [],
   "source": [
    "def nn_callbacks():\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        patience=5, verbose=1, restore_best_weights=True, min_delta=1e-4\n",
    "    )\n",
    "    rlp = keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1)\n",
    "    return [es, rlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:03.291255Z",
     "iopub.status.busy": "2021-12-18T10:26:03.290772Z",
     "iopub.status.idle": "2021-12-18T10:26:06.683984Z",
     "shell.execute_reply": "2021-12-18T10:26:06.683318Z",
     "shell.execute_reply.started": "2021-12-18T10:26:03.291228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:26:03.297998: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-18 10:26:03.301087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-18 10:26:03.349748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.350538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-12-18 10:26:03.350594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-18 10:26:03.391551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-18 10:26:03.391647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-18 10:26:03.419945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-18 10:26:03.441482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-18 10:26:03.484956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-18 10:26:03.493041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-18 10:26:03.496031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-18 10:26:03.496200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.496914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.498467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-18 10:26:03.499843: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-18 10:26:03.500862: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-18 10:26:03.501015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.501617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-12-18 10:26:03.501659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-18 10:26:03.501731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-18 10:26:03.501758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-18 10:26:03.501773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-18 10:26:03.501788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-18 10:26:03.501811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-18 10:26:03.501828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-18 10:26:03.501844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-18 10:26:03.501919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.502534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:03.503070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-18 10:26:03.503980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-18 10:26:04.941214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-18 10:26:04.941259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-18 10:26:04.941269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-18 10:26:04.943402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:04.944075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:04.944745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 10:26:04.945325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "2021-12-18 10:26:05.486527: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "d_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "d_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teacher Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:06.685666Z",
     "iopub.status.busy": "2021-12-18T10:26:06.685143Z",
     "iopub.status.idle": "2021-12-18T10:26:07.86074Z",
     "shell.execute_reply": "2021-12-18T10:26:07.860029Z",
     "shell.execute_reply.started": "2021-12-18T10:26:06.685624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 0s 0us/step\n",
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 20,029,514\n",
      "Trainable params: 20,029,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_teacher_model(name='teacher'):\n",
    "    base_model = keras.applications.VGG19(input_shape=IMAGE_SIZE, include_top=False)\n",
    "    base_model.trainable = True\n",
    "    return keras.models.Sequential([\n",
    "            base_model,        \n",
    "            L.GlobalAvgPool2D(),        \n",
    "            L.Dense(N_CLASSES)\n",
    "        ], name=name\n",
    "    )\n",
    "        \n",
    "\n",
    "teacher_model = build_teacher_model()\n",
    "teacher_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:07.862081Z",
     "iopub.status.busy": "2021-12-18T10:26:07.861842Z",
     "iopub.status.idle": "2021-12-18T10:26:08.024919Z",
     "shell.execute_reply": "2021-12-18T10:26:08.02423Z",
     "shell.execute_reply.started": "2021-12-18T10:26:07.862048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"student\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 519,434\n",
      "Trainable params: 519,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_student_model(name='student'):\n",
    "    return keras.models.Sequential([\n",
    "        L.Conv2D(64, 3, input_shape=IMAGE_SIZE, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        L.MaxPool2D(pool_size=2),\n",
    "        L.GlobalAvgPool2D(),\n",
    "        L.Dense(N_CLASSES),\n",
    "    ],name=name) \n",
    "\n",
    "student_model = build_student_model()\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:26:08.027495Z",
     "iopub.status.busy": "2021-12-18T10:26:08.027255Z",
     "iopub.status.idle": "2021-12-18T10:30:55.509112Z",
     "shell.execute_reply": "2021-12-18T10:30:55.508391Z",
     "shell.execute_reply.started": "2021-12-18T10:26:08.027465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:26:08.078313: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n",
      "2021-12-18 10:26:08.813614: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:26:10.360631: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-18 10:26:10.370155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000200000 Hz\n",
      "2021-12-18 10:26:10.573702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-18 10:26:11.297271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-18 10:26:11.328507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 25s 161ms/step - loss: 1.8169 - accuracy: 0.3511 - val_loss: 0.9692 - val_accuracy: 0.6605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:26:34.532608: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.9064 - accuracy: 0.6833 - val_loss: 0.8057 - val_accuracy: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 10:26:48.406240: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "98/98 [==============================] - 13s 131ms/step - loss: 0.7546 - accuracy: 0.7377 - val_loss: 0.7320 - val_accuracy: 0.7440\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.6660 - accuracy: 0.7672 - val_loss: 0.6994 - val_accuracy: 0.7546\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.6116 - accuracy: 0.7846 - val_loss: 0.6523 - val_accuracy: 0.7705\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.5570 - accuracy: 0.8060 - val_loss: 0.6370 - val_accuracy: 0.7760\n",
      "Epoch 7/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.5147 - accuracy: 0.8228 - val_loss: 0.6291 - val_accuracy: 0.7858\n",
      "Epoch 8/25\n",
      "98/98 [==============================] - 13s 134ms/step - loss: 0.4836 - accuracy: 0.8342 - val_loss: 0.6223 - val_accuracy: 0.7854\n",
      "Epoch 9/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.4532 - accuracy: 0.8431 - val_loss: 0.6160 - val_accuracy: 0.7911\n",
      "Epoch 10/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.4280 - accuracy: 0.8551 - val_loss: 0.6059 - val_accuracy: 0.7959\n",
      "Epoch 11/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.3950 - accuracy: 0.8664 - val_loss: 0.5943 - val_accuracy: 0.8012\n",
      "Epoch 12/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.3690 - accuracy: 0.8750 - val_loss: 0.5861 - val_accuracy: 0.8056\n",
      "Epoch 13/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.3463 - accuracy: 0.8828 - val_loss: 0.6043 - val_accuracy: 0.8021\n",
      "Epoch 14/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.3238 - accuracy: 0.8908 - val_loss: 0.5955 - val_accuracy: 0.8032\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 15/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.2836 - accuracy: 0.9054 - val_loss: 0.5700 - val_accuracy: 0.8142\n",
      "Epoch 16/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.2702 - accuracy: 0.9118 - val_loss: 0.5740 - val_accuracy: 0.8145\n",
      "Epoch 17/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.2646 - accuracy: 0.9127 - val_loss: 0.5762 - val_accuracy: 0.8146\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 18/25\n",
      "98/98 [==============================] - 13s 133ms/step - loss: 0.2610 - accuracy: 0.9143 - val_loss: 0.5703 - val_accuracy: 0.8153\n",
      "Epoch 19/25\n",
      "98/98 [==============================] - 13s 132ms/step - loss: 0.2558 - accuracy: 0.9175 - val_loss: 0.5703 - val_accuracy: 0.8155\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 20/25\n",
      "98/98 [==============================] - 13s 133ms/step - loss: 0.2543 - accuracy: 0.9184 - val_loss: 0.5701 - val_accuracy: 0.8153\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "teacher_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5), \n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = teacher_model.fit(\n",
    "    d_train.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    epochs=T_EPOCHS,\n",
    "    callbacks=nn_callbacks(), \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:30:55.515237Z",
     "iopub.status.busy": "2021-12-18T10:30:55.513336Z",
     "iopub.status.idle": "2021-12-18T10:30:55.540057Z",
     "shell.execute_reply": "2021-12-18T10:30:55.539143Z",
     "shell.execute_reply.started": "2021-12-18T10:30:55.515193Z"
    }
   },
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher, activation):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.activation = activation\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=10,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student.compile(optimizer=optimizer, metrics=metrics, loss=student_loss_fn)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                self.activation(teacher_predictions / self.temperature, axis=1),\n",
    "                self.activation(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        student_predictions = self.student(x, training=False)\n",
    "        \n",
    "        student_loss = self.student_loss_fn(y, student_predictions)\n",
    "        distillation_loss = self.distillation_loss_fn(\n",
    "            self.activation(teacher_predictions / self.temperature, axis=1),\n",
    "            self.activation(student_predictions / self.temperature, axis=1),\n",
    "        )\n",
    "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "        \n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.student(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-18T10:30:55.544466Z",
     "iopub.status.busy": "2021-12-18T10:30:55.543752Z",
     "iopub.status.idle": "2021-12-18T10:34:30.124781Z",
     "shell.execute_reply": "2021-12-18T10:34:30.124002Z",
     "shell.execute_reply.started": "2021-12-18T10:30:55.544429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 12s 110ms/step - accuracy: 0.1190 - student_loss: 2.2052 - distillation_loss: 0.0011 - loss: 1.5440 - val_accuracy: 0.2149 - val_student_loss: 2.0421 - val_distillation_loss: 0.0010 - val_loss: 1.4298\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.2523 - student_loss: 1.8369 - distillation_loss: 8.3994e-04 - loss: 1.2861 - val_accuracy: 0.3400 - val_student_loss: 1.7790 - val_distillation_loss: 6.9673e-04 - val_loss: 1.2455\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 10s 105ms/step - accuracy: 0.3751 - student_loss: 1.5843 - distillation_loss: 7.0287e-04 - loss: 1.1092 - val_accuracy: 0.4357 - val_student_loss: 1.5271 - val_distillation_loss: 7.2431e-04 - val_loss: 1.0692\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 10s 104ms/step - accuracy: 0.4690 - student_loss: 1.3955 - distillation_loss: 6.2960e-04 - loss: 0.9770 - val_accuracy: 0.5139 - val_student_loss: 1.3352 - val_distillation_loss: 6.2460e-04 - val_loss: 0.9348\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 10s 104ms/step - accuracy: 0.5295 - student_loss: 1.2415 - distillation_loss: 5.5611e-04 - loss: 0.8692 - val_accuracy: 0.5687 - val_student_loss: 1.0712 - val_distillation_loss: 5.3939e-04 - val_loss: 0.7500\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 10s 105ms/step - accuracy: 0.5856 - student_loss: 1.1273 - distillation_loss: 5.1241e-04 - loss: 0.7892 - val_accuracy: 0.6082 - val_student_loss: 1.1146 - val_distillation_loss: 4.7842e-04 - val_loss: 0.7804\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 10s 105ms/step - accuracy: 0.6277 - student_loss: 1.0099 - distillation_loss: 4.6430e-04 - loss: 0.7071 - val_accuracy: 0.6411 - val_student_loss: 1.1694 - val_distillation_loss: 4.5738e-04 - val_loss: 0.8187\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 10s 104ms/step - accuracy: 0.6858 - student_loss: 0.8451 - distillation_loss: 3.9362e-04 - loss: 0.5917 - val_accuracy: 0.6717 - val_student_loss: 0.9118 - val_distillation_loss: 3.8067e-04 - val_loss: 0.6383\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7024 - student_loss: 0.8118 - distillation_loss: 3.7450e-04 - loss: 0.5684 - val_accuracy: 0.6753 - val_student_loss: 0.9768 - val_distillation_loss: 3.7221e-04 - val_loss: 0.6838\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7142 - student_loss: 0.7868 - distillation_loss: 3.6613e-04 - loss: 0.5509 - val_accuracy: 0.6795 - val_student_loss: 0.8892 - val_distillation_loss: 3.5733e-04 - val_loss: 0.6226\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7212 - student_loss: 0.7672 - distillation_loss: 3.6043e-04 - loss: 0.5371 - val_accuracy: 0.6822 - val_student_loss: 0.8692 - val_distillation_loss: 3.8003e-04 - val_loss: 0.6085\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7296 - student_loss: 0.7450 - distillation_loss: 3.5502e-04 - loss: 0.5216 - val_accuracy: 0.6917 - val_student_loss: 0.8416 - val_distillation_loss: 3.5005e-04 - val_loss: 0.5892\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 10s 105ms/step - accuracy: 0.7386 - student_loss: 0.7288 - distillation_loss: 3.5132e-04 - loss: 0.5103 - val_accuracy: 0.6950 - val_student_loss: 0.7847 - val_distillation_loss: 3.4194e-04 - val_loss: 0.5494\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7448 - student_loss: 0.7079 - distillation_loss: 3.4747e-04 - loss: 0.4956 - val_accuracy: 0.6983 - val_student_loss: 0.7611 - val_distillation_loss: 3.5645e-04 - val_loss: 0.5329\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 10s 107ms/step - accuracy: 0.7518 - student_loss: 0.6921 - distillation_loss: 3.4357e-04 - loss: 0.4846 - val_accuracy: 0.7036 - val_student_loss: 0.8460 - val_distillation_loss: 3.4598e-04 - val_loss: 0.5923\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7554 - student_loss: 0.6760 - distillation_loss: 3.4227e-04 - loss: 0.4733 - val_accuracy: 0.7061 - val_student_loss: 0.8631 - val_distillation_loss: 3.1594e-04 - val_loss: 0.6043\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7667 - student_loss: 0.6473 - distillation_loss: 3.3656e-04 - loss: 0.4532 - val_accuracy: 0.7089 - val_student_loss: 0.8830 - val_distillation_loss: 3.2733e-04 - val_loss: 0.6182\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7685 - student_loss: 0.6422 - distillation_loss: 3.3465e-04 - loss: 0.4497 - val_accuracy: 0.7094 - val_student_loss: 0.9002 - val_distillation_loss: 3.4015e-04 - val_loss: 0.6303\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 10s 106ms/step - accuracy: 0.7708 - student_loss: 0.6377 - distillation_loss: 3.3303e-04 - loss: 0.4465 - val_accuracy: 0.7094 - val_student_loss: 0.8550 - val_distillation_loss: 3.3997e-04 - val_loss: 0.5986\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(student_model, teacher_model, tf.nn.softmax)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.7,\n",
    "    temperature=100,\n",
    ")\n",
    "history_distillation = distiller.fit(\n",
    "    d_train.shuffle(1024, 19).batch(BATCH_SIZE), \n",
    "    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n",
    "    epochs=S_EPOCHS, callbacks=nn_callbacks(), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T10:34:30.126439Z",
     "iopub.status.busy": "2021-12-18T10:34:30.126155Z",
     "iopub.status.idle": "2021-12-18T10:34:32.867598Z",
     "shell.execute_reply": "2021-12-18T10:34:32.86684Z",
     "shell.execute_reply.started": "2021-12-18T10:34:30.126404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model:\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5700 - accuracy: 0.8142\n",
      "File Size is : 229.35 MB\n",
      "Distilled Model:\n",
      "20/20 [==============================] - 1s 21ms/step - loss: 0.8519 - accuracy: 0.6982\n",
      "File Size is : 6.09 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('Teacher Model:')\n",
    "teacher_model.save('teacher.h5')\n",
    "teacher_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\n",
    "print(\"File Size is :\", round(os.path.getsize('teacher.h5')/1024**2, 2), \"MB\")\n",
    "print('Distilled Model:')\n",
    "student_model.save('student.h5')\n",
    "student_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\n",
    "print(\"File Size is :\", round(os.path.getsize('student.h5')/1024**2, 2), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**\n",
    "\n",
    "* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)\n",
    "* [Implementation of classical Knowledge Distillation](https://keras.io/examples/vision/knowledge_distillation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
