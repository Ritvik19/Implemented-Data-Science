{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/ritvik1909/knowledge-distillation?scriptVersionId=82656214\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Knowledge Distillation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers as L","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T10:25:52.52012Z","iopub.execute_input":"2021-12-18T10:25:52.520446Z","iopub.status.idle":"2021-12-18T10:25:56.948991Z","shell.execute_reply.started":"2021-12-18T10:25:52.52037Z","shell.execute_reply":"2021-12-18T10:25:56.948157Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2021-12-18 10:25:53.118143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"(x_train, y_train), (x_valid, y_valid) = keras.datasets.cifar10.load_data()\nx_train = x_train/255.0\nx_valid = x_valid/255.0\n# x_train = np.expand_dims(x_train, axis=3)\n# x_valid = np.expand_dims(x_valid, axis=3)\ny_train = keras.utils.to_categorical(y_train)\ny_valid = keras.utils.to_categorical(y_valid)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:25:56.95092Z","iopub.execute_input":"2021-12-18T10:25:56.951187Z","iopub.status.idle":"2021-12-18T10:26:03.263098Z","shell.execute_reply.started":"2021-12-18T10:25:56.951153Z","shell.execute_reply":"2021-12-18T10:26:03.262373Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"T_EPOCHS = 25\nS_EPOCHS = 20\nIMAGE_SIZE = x_train.shape[1:]\nBATCH_SIZE = 512\nN_CLASSES = y_train.shape[-1]\nIMAGE_SIZE, N_CLASSES","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:26:03.26451Z","iopub.execute_input":"2021-12-18T10:26:03.26476Z","iopub.status.idle":"2021-12-18T10:26:03.273839Z","shell.execute_reply.started":"2021-12-18T10:26:03.264728Z","shell.execute_reply":"2021-12-18T10:26:03.273204Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((32, 32, 3), 10)"},"metadata":{}}]},{"cell_type":"code","source":"def nn_callbacks():\n    es = keras.callbacks.EarlyStopping(\n        patience=5, verbose=1, restore_best_weights=True, min_delta=1e-4\n    )\n    rlp = keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1)\n    return [es, rlp]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:26:03.275174Z","iopub.execute_input":"2021-12-18T10:26:03.275635Z","iopub.status.idle":"2021-12-18T10:26:03.28714Z","shell.execute_reply.started":"2021-12-18T10:26:03.275603Z","shell.execute_reply":"2021-12-18T10:26:03.286353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"d_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nd_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n\ndel x_train, x_valid, y_train, y_valid","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:26:03.290772Z","iopub.execute_input":"2021-12-18T10:26:03.291255Z","iopub.status.idle":"2021-12-18T10:26:06.683984Z","shell.execute_reply.started":"2021-12-18T10:26:03.291228Z","shell.execute_reply":"2021-12-18T10:26:06.683318Z"},"_kg_hide-output":true,"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2021-12-18 10:26:03.297998: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-12-18 10:26:03.301087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-12-18 10:26:03.349748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.350538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-12-18 10:26:03.350594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-12-18 10:26:03.391551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-12-18 10:26:03.391647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-12-18 10:26:03.419945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-12-18 10:26:03.441482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-12-18 10:26:03.484956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-12-18 10:26:03.493041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-12-18 10:26:03.496031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-12-18 10:26:03.496200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.496914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.498467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-12-18 10:26:03.499843: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-12-18 10:26:03.500862: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-12-18 10:26:03.501015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.501617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-12-18 10:26:03.501659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-12-18 10:26:03.501731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-12-18 10:26:03.501758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-12-18 10:26:03.501773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-12-18 10:26:03.501788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-12-18 10:26:03.501811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-12-18 10:26:03.501828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-12-18 10:26:03.501844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-12-18 10:26:03.501919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.502534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:03.503070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-12-18 10:26:03.503980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-12-18 10:26:04.941214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-12-18 10:26:04.941259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-12-18 10:26:04.941269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-12-18 10:26:04.943402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:04.944075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:04.944745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-18 10:26:04.945325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n2021-12-18 10:26:05.486527: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building the Models","metadata":{}},{"cell_type":"markdown","source":"**Teacher Model**","metadata":{}},{"cell_type":"code","source":"def build_teacher_model(name='teacher'):\n    base_model = keras.applications.VGG19(input_shape=IMAGE_SIZE, include_top=False)\n    base_model.trainable = True\n    return keras.models.Sequential([\n            base_model,        \n            L.GlobalAvgPool2D(),        \n            L.Dense(N_CLASSES)\n        ], name=name\n    )\n        \n\nteacher_model = build_teacher_model()\nteacher_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:26:06.685143Z","iopub.execute_input":"2021-12-18T10:26:06.685666Z","iopub.status.idle":"2021-12-18T10:26:07.86074Z","shell.execute_reply.started":"2021-12-18T10:26:06.685624Z","shell.execute_reply":"2021-12-18T10:26:07.860029Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 0s 0us/step\nModel: \"teacher\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg19 (Functional)           (None, 1, 1, 512)         20024384  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                5130      \n=================================================================\nTotal params: 20,029,514\nTrainable params: 20,029,514\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Student Model**","metadata":{}},{"cell_type":"code","source":"def build_student_model(name='student'):\n    return keras.models.Sequential([\n        L.Conv2D(64, 3, input_shape=IMAGE_SIZE, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.MaxPool2D(pool_size=2),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.MaxPool2D(pool_size=2),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.MaxPool2D(pool_size=2),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.MaxPool2D(pool_size=2),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.Conv2D(64, 3, padding='same', activation='relu'),\n        L.MaxPool2D(pool_size=2),\n        L.GlobalAvgPool2D(),\n        L.Dense(N_CLASSES),\n    ],name=name) \n\nstudent_model = build_student_model()\nstudent_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:26:07.861842Z","iopub.execute_input":"2021-12-18T10:26:07.862081Z","iopub.status.idle":"2021-12-18T10:26:08.024919Z","shell.execute_reply.started":"2021-12-18T10:26:07.862048Z","shell.execute_reply":"2021-12-18T10:26:08.02423Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"student\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 64)        1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 8, 8, 64)          36928     \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 4, 4, 64)          36928     \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 2, 2, 64)          36928     \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 2, 2, 64)          36928     \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 519,434\nTrainable params: 519,434\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training Teacher","metadata":{}},{"cell_type":"code","source":"teacher_model.compile(\n    optimizer=keras.optimizers.Adam(1e-5), \n    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n\nhistory = teacher_model.fit(\n    d_train.shuffle(1024, 19).batch(BATCH_SIZE),\n    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n    epochs=T_EPOCHS,\n    callbacks=nn_callbacks(), \n    batch_size=BATCH_SIZE\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-18T10:26:08.027255Z","iopub.execute_input":"2021-12-18T10:26:08.027495Z","iopub.status.idle":"2021-12-18T10:30:55.509112Z","shell.execute_reply.started":"2021-12-18T10:26:08.027465Z","shell.execute_reply":"2021-12-18T10:30:55.508391Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2021-12-18 10:26:08.078313: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n2021-12-18 10:26:08.813614: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"2021-12-18 10:26:10.360631: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-12-18 10:26:10.370155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000200000 Hz\n2021-12-18 10:26:10.573702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-12-18 10:26:11.297271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-12-18 10:26:11.328507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","output_type":"stream"},{"name":"stdout","text":"98/98 [==============================] - 25s 161ms/step - loss: 1.8169 - accuracy: 0.3511 - val_loss: 0.9692 - val_accuracy: 0.6605\n","output_type":"stream"},{"name":"stderr","text":"2021-12-18 10:26:34.532608: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.9064 - accuracy: 0.6833 - val_loss: 0.8057 - val_accuracy: 0.7169\n","output_type":"stream"},{"name":"stderr","text":"2021-12-18 10:26:48.406240: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1228800000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/25\n98/98 [==============================] - 13s 131ms/step - loss: 0.7546 - accuracy: 0.7377 - val_loss: 0.7320 - val_accuracy: 0.7440\nEpoch 4/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.6660 - accuracy: 0.7672 - val_loss: 0.6994 - val_accuracy: 0.7546\nEpoch 5/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.6116 - accuracy: 0.7846 - val_loss: 0.6523 - val_accuracy: 0.7705\nEpoch 6/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.5570 - accuracy: 0.8060 - val_loss: 0.6370 - val_accuracy: 0.7760\nEpoch 7/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.5147 - accuracy: 0.8228 - val_loss: 0.6291 - val_accuracy: 0.7858\nEpoch 8/25\n98/98 [==============================] - 13s 134ms/step - loss: 0.4836 - accuracy: 0.8342 - val_loss: 0.6223 - val_accuracy: 0.7854\nEpoch 9/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.4532 - accuracy: 0.8431 - val_loss: 0.6160 - val_accuracy: 0.7911\nEpoch 10/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.4280 - accuracy: 0.8551 - val_loss: 0.6059 - val_accuracy: 0.7959\nEpoch 11/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.3950 - accuracy: 0.8664 - val_loss: 0.5943 - val_accuracy: 0.8012\nEpoch 12/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.3690 - accuracy: 0.8750 - val_loss: 0.5861 - val_accuracy: 0.8056\nEpoch 13/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.3463 - accuracy: 0.8828 - val_loss: 0.6043 - val_accuracy: 0.8021\nEpoch 14/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.3238 - accuracy: 0.8908 - val_loss: 0.5955 - val_accuracy: 0.8032\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\nEpoch 15/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.2836 - accuracy: 0.9054 - val_loss: 0.5700 - val_accuracy: 0.8142\nEpoch 16/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.2702 - accuracy: 0.9118 - val_loss: 0.5740 - val_accuracy: 0.8145\nEpoch 17/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.2646 - accuracy: 0.9127 - val_loss: 0.5762 - val_accuracy: 0.8146\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\nEpoch 18/25\n98/98 [==============================] - 13s 133ms/step - loss: 0.2610 - accuracy: 0.9143 - val_loss: 0.5703 - val_accuracy: 0.8153\nEpoch 19/25\n98/98 [==============================] - 13s 132ms/step - loss: 0.2558 - accuracy: 0.9175 - val_loss: 0.5703 - val_accuracy: 0.8155\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\nEpoch 20/25\n98/98 [==============================] - 13s 133ms/step - loss: 0.2543 - accuracy: 0.9184 - val_loss: 0.5701 - val_accuracy: 0.8153\nRestoring model weights from the end of the best epoch.\nEpoch 00020: early stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Distillation in Action","metadata":{}},{"cell_type":"code","source":"class Distiller(keras.Model):\n    def __init__(self, student, teacher, activation):\n        super().__init__()\n        self.teacher = teacher\n        self.student = student\n        self.activation = activation\n\n    def compile(\n        self,\n        optimizer,\n        metrics,\n        student_loss_fn,\n        distillation_loss_fn,\n        alpha=0.1,\n        temperature=10,\n    ):\n        \"\"\" Configure the distiller.\n\n        Args:\n            optimizer: Keras optimizer for the student weights\n            metrics: Keras metrics for evaluation\n            student_loss_fn: Loss function of difference between student\n                predictions and ground-truth\n            distillation_loss_fn: Loss function of difference between soft\n                student predictions and soft teacher predictions\n            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n            temperature: Temperature for softening probability distributions.\n                Larger temperature gives softer distributions.\n        \"\"\"\n        super().compile(optimizer=optimizer, metrics=metrics)\n        self.student.compile(optimizer=optimizer, metrics=metrics, loss=student_loss_fn)\n        self.student_loss_fn = student_loss_fn\n        self.distillation_loss_fn = distillation_loss_fn\n        self.alpha = alpha\n        self.temperature = temperature\n\n    def train_step(self, data):\n        x, y = data\n        teacher_predictions = self.teacher(x, training=False)\n\n        with tf.GradientTape() as tape:\n            student_predictions = self.student(x, training=True)\n            student_loss = self.student_loss_fn(y, student_predictions)\n            distillation_loss = self.distillation_loss_fn(\n                self.activation(teacher_predictions / self.temperature, axis=1),\n                self.activation(student_predictions / self.temperature, axis=1),\n            )\n            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n\n        trainable_vars = self.student.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        self.compiled_metrics.update_state(y, student_predictions)\n\n        results = {m.name: m.result() for m in self.metrics}\n        results.update(\n            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n        )\n        return results\n\n    def test_step(self, data):\n        x, y = data\n        teacher_predictions = self.teacher(x, training=False)\n        student_predictions = self.student(x, training=False)\n        \n        student_loss = self.student_loss_fn(y, student_predictions)\n        distillation_loss = self.distillation_loss_fn(\n            self.activation(teacher_predictions / self.temperature, axis=1),\n            self.activation(student_predictions / self.temperature, axis=1),\n        )\n        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n        \n        self.compiled_metrics.update_state(y, student_predictions)\n\n        results = {m.name: m.result() for m in self.metrics}\n        results.update(\n            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, \"loss\": loss}\n        )\n        return results\n    \n    def call(self, x):\n        return self.student(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:30:55.513336Z","iopub.execute_input":"2021-12-18T10:30:55.515237Z","iopub.status.idle":"2021-12-18T10:30:55.540057Z","shell.execute_reply.started":"2021-12-18T10:30:55.515193Z","shell.execute_reply":"2021-12-18T10:30:55.539143Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"distiller = Distiller(student_model, teacher_model, tf.nn.softmax)\ndistiller.compile(\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy'],\n    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n    distillation_loss_fn=keras.losses.KLDivergence(),\n    alpha=0.7,\n    temperature=100,\n)\nhistory_distillation = distiller.fit(\n    d_train.shuffle(1024, 19).batch(BATCH_SIZE), \n    validation_data=d_valid.shuffle(1024, 19).batch(BATCH_SIZE),\n    epochs=S_EPOCHS, callbacks=nn_callbacks(), batch_size=BATCH_SIZE\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-18T10:30:55.543752Z","iopub.execute_input":"2021-12-18T10:30:55.544466Z","iopub.status.idle":"2021-12-18T10:34:30.124781Z","shell.execute_reply.started":"2021-12-18T10:30:55.544429Z","shell.execute_reply":"2021-12-18T10:34:30.124002Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/20\n98/98 [==============================] - 12s 110ms/step - accuracy: 0.1190 - student_loss: 2.2052 - distillation_loss: 0.0011 - loss: 1.5440 - val_accuracy: 0.2149 - val_student_loss: 2.0421 - val_distillation_loss: 0.0010 - val_loss: 1.4298\nEpoch 2/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.2523 - student_loss: 1.8369 - distillation_loss: 8.3994e-04 - loss: 1.2861 - val_accuracy: 0.3400 - val_student_loss: 1.7790 - val_distillation_loss: 6.9673e-04 - val_loss: 1.2455\nEpoch 3/20\n98/98 [==============================] - 10s 105ms/step - accuracy: 0.3751 - student_loss: 1.5843 - distillation_loss: 7.0287e-04 - loss: 1.1092 - val_accuracy: 0.4357 - val_student_loss: 1.5271 - val_distillation_loss: 7.2431e-04 - val_loss: 1.0692\nEpoch 4/20\n98/98 [==============================] - 10s 104ms/step - accuracy: 0.4690 - student_loss: 1.3955 - distillation_loss: 6.2960e-04 - loss: 0.9770 - val_accuracy: 0.5139 - val_student_loss: 1.3352 - val_distillation_loss: 6.2460e-04 - val_loss: 0.9348\nEpoch 5/20\n98/98 [==============================] - 10s 104ms/step - accuracy: 0.5295 - student_loss: 1.2415 - distillation_loss: 5.5611e-04 - loss: 0.8692 - val_accuracy: 0.5687 - val_student_loss: 1.0712 - val_distillation_loss: 5.3939e-04 - val_loss: 0.7500\nEpoch 6/20\n98/98 [==============================] - 10s 105ms/step - accuracy: 0.5856 - student_loss: 1.1273 - distillation_loss: 5.1241e-04 - loss: 0.7892 - val_accuracy: 0.6082 - val_student_loss: 1.1146 - val_distillation_loss: 4.7842e-04 - val_loss: 0.7804\nEpoch 7/20\n98/98 [==============================] - 10s 105ms/step - accuracy: 0.6277 - student_loss: 1.0099 - distillation_loss: 4.6430e-04 - loss: 0.7071 - val_accuracy: 0.6411 - val_student_loss: 1.1694 - val_distillation_loss: 4.5738e-04 - val_loss: 0.8187\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 8/20\n98/98 [==============================] - 10s 104ms/step - accuracy: 0.6858 - student_loss: 0.8451 - distillation_loss: 3.9362e-04 - loss: 0.5917 - val_accuracy: 0.6717 - val_student_loss: 0.9118 - val_distillation_loss: 3.8067e-04 - val_loss: 0.6383\nEpoch 9/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7024 - student_loss: 0.8118 - distillation_loss: 3.7450e-04 - loss: 0.5684 - val_accuracy: 0.6753 - val_student_loss: 0.9768 - val_distillation_loss: 3.7221e-04 - val_loss: 0.6838\nEpoch 10/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7142 - student_loss: 0.7868 - distillation_loss: 3.6613e-04 - loss: 0.5509 - val_accuracy: 0.6795 - val_student_loss: 0.8892 - val_distillation_loss: 3.5733e-04 - val_loss: 0.6226\nEpoch 11/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7212 - student_loss: 0.7672 - distillation_loss: 3.6043e-04 - loss: 0.5371 - val_accuracy: 0.6822 - val_student_loss: 0.8692 - val_distillation_loss: 3.8003e-04 - val_loss: 0.6085\nEpoch 12/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7296 - student_loss: 0.7450 - distillation_loss: 3.5502e-04 - loss: 0.5216 - val_accuracy: 0.6917 - val_student_loss: 0.8416 - val_distillation_loss: 3.5005e-04 - val_loss: 0.5892\nEpoch 13/20\n98/98 [==============================] - 10s 105ms/step - accuracy: 0.7386 - student_loss: 0.7288 - distillation_loss: 3.5132e-04 - loss: 0.5103 - val_accuracy: 0.6950 - val_student_loss: 0.7847 - val_distillation_loss: 3.4194e-04 - val_loss: 0.5494\nEpoch 14/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7448 - student_loss: 0.7079 - distillation_loss: 3.4747e-04 - loss: 0.4956 - val_accuracy: 0.6983 - val_student_loss: 0.7611 - val_distillation_loss: 3.5645e-04 - val_loss: 0.5329\nEpoch 15/20\n98/98 [==============================] - 10s 107ms/step - accuracy: 0.7518 - student_loss: 0.6921 - distillation_loss: 3.4357e-04 - loss: 0.4846 - val_accuracy: 0.7036 - val_student_loss: 0.8460 - val_distillation_loss: 3.4598e-04 - val_loss: 0.5923\nEpoch 16/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7554 - student_loss: 0.6760 - distillation_loss: 3.4227e-04 - loss: 0.4733 - val_accuracy: 0.7061 - val_student_loss: 0.8631 - val_distillation_loss: 3.1594e-04 - val_loss: 0.6043\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\nEpoch 17/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7667 - student_loss: 0.6473 - distillation_loss: 3.3656e-04 - loss: 0.4532 - val_accuracy: 0.7089 - val_student_loss: 0.8830 - val_distillation_loss: 3.2733e-04 - val_loss: 0.6182\nEpoch 18/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7685 - student_loss: 0.6422 - distillation_loss: 3.3465e-04 - loss: 0.4497 - val_accuracy: 0.7094 - val_student_loss: 0.9002 - val_distillation_loss: 3.4015e-04 - val_loss: 0.6303\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\nEpoch 19/20\n98/98 [==============================] - 10s 106ms/step - accuracy: 0.7708 - student_loss: 0.6377 - distillation_loss: 3.3303e-04 - loss: 0.4465 - val_accuracy: 0.7094 - val_student_loss: 0.8550 - val_distillation_loss: 3.3997e-04 - val_loss: 0.5986\nRestoring model weights from the end of the best epoch.\nEpoch 00019: early stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Comparison","metadata":{}},{"cell_type":"code","source":"import os\n\nprint('Teacher Model:')\nteacher_model.save('teacher.h5')\nteacher_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\nprint(\"File Size is :\", round(os.path.getsize('teacher.h5')/1024**2, 2), \"MB\")\nprint('Distilled Model:')\nstudent_model.save('student.h5')\nstudent_model.evaluate(d_valid.shuffle(1024, 19).batch(BATCH_SIZE))\nprint(\"File Size is :\", round(os.path.getsize('student.h5')/1024**2, 2), \"MB\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T10:34:30.126155Z","iopub.execute_input":"2021-12-18T10:34:30.126439Z","iopub.status.idle":"2021-12-18T10:34:32.867598Z","shell.execute_reply.started":"2021-12-18T10:34:30.126404Z","shell.execute_reply":"2021-12-18T10:34:32.86684Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Teacher Model:\n20/20 [==============================] - 1s 42ms/step - loss: 0.5700 - accuracy: 0.8142\nFile Size is : 229.35 MB\nDistilled Model:\n20/20 [==============================] - 1s 21ms/step - loss: 0.8519 - accuracy: 0.6982\nFile Size is : 6.09 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Reference**\n\n* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)\n* [Implementation of classical Knowledge Distillation](https://keras.io/examples/vision/knowledge_distillation/)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}